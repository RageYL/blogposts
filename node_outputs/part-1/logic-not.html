
	<!DOCTYPE html>
	<html>
	<head>
		<meta charset="UTF-8">

		<!--
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/7.0.0/normalize.min.css" />
		-->

		<link rel="stylesheet" href="/node_sources/part-x/index-v1.css">
		<link rel="stylesheet" href="/node_modules/katex/dist/katex.min.css">
		<link rel="stylesheet" href="/node_modules/highlight.js/styles/default.css">

		<link rel="stylesheet" href="/node_modules/slick-carousel/slick/slick.css">
		<link rel="stylesheet" href="/node_modules/slick-carousel/slick/slick-theme.css">

		<script src="/node_modules/lodash/lodash.min.js"></script>
		<script src="/node_modules/highcharts/highcharts.js"></script>
		<script src="/node_modules/jquery/dist/jquery.min.js"></script>
		<script src="/node_modules/slick-carousel/slick/slick.min.js"></script>

		<link rel="stylesheet" href="//code.jquery.com/ui/1.12.1/themes/base/jquery-ui.css">
		<script src="https://code.jquery.com/ui/1.12.1/jquery-ui.js"></script>
	</head>
	<body>
		<div id="content">
			<h1>Pixel is black model</h1>
<p>Now that we are confortable with small networks, let's look at one of their
weaknesses.</p>
<p>Let's create a model that classify an input pixel as black or not black:</p>
<ul>
<li>1 if the pixel is black</li>
<li>0 otherwise</li>
</ul>
<p>This problem seems identical to the previous ones, but there is a subtlety that
require our attention:</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-equations.png" alt=""></p>
<p>We can see that if we input a black pixel, the weight is multiplied by 0. No
matter its value, the result will always be 0.</p>
<p>Fortunately there is an easy fix: biases.</p>
<h1>Biases</h1>
<p>A bias is just another neuron we add to the inputs.</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-bias.png" alt=""></p>
<p>It has a fixed value of 1.</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-bias-value.png" alt=""></p>
<p>And like any other neuron, it has a weight.</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-bias-weight.png" alt=""></p>
<p>The equation is the same as a network with two inputs:</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-bias-equation.png" alt=""></p>
<p>We can see this simple little trick solve our problem:</p>
<p><img src="/node_outputs/part-1/images-js/nnet-not-bias-solutions.png" alt=""></p>
<h1>Code</h1>
<p>Remember the <code>use_bias</code> parameter we didn't talk about ? It does exactly what
its name implies. Using a bias is almost always useful, so we will set it to
<code>True</code>, its default value.</p>
<pre><code class="language-python">pixel_is_black_m = Sequential()
pixel_is_black_m.add(Dense(<span class="hljs-number">1</span>, use_bias = <span class="hljs-keyword">True</span>, input_shape = (<span class="hljs-number">1</span>,)))

pixel_is_black_x = [BLACK, WHITE]
pixel_is_black_y = [<span class="hljs-number">1</span>,     <span class="hljs-number">0</span>]

train(
    pixel_is_black_m,
    pixel_is_black_x,
    pixel_is_black_y
)

pixel_is_black_m.predict_classes(pixel_is_black_x)

<span class="hljs-comment">#&gt; array([[1],</span>
<span class="hljs-comment">#&gt;        [0]], dtype=int32)</span>

pixel_is_black_m.predict(pixel_is_black_x)

<span class="hljs-comment">#&gt; array([[ 0.97386539],</span>
<span class="hljs-comment">#&gt;        [ 0.00688618]], dtype=float32)</span>
</code></pre>
<p>Once again, let's update our implementation:</p>
<pre><code class="language-python">[w], b = pixel_is_black_m.get_weights()
w

<span class="hljs-comment">#&gt; array([-0.96697921], dtype=float32)</span>

b

<span class="hljs-comment">#&gt; array([ 0.97386539], dtype=float32)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">neuron</span><span class="hljs-params">(x)</span>:</span>
    y  = <span class="hljs-number">1</span> * b
    y += x * w
    <span class="hljs-keyword">return</span> y

neuron(BLACK)

<span class="hljs-comment">#&gt; array([[ 0.97386539]], dtype=float32)</span>

neuron(WHITE)

<span class="hljs-comment">#&gt; array([[ 0.00688618]], dtype=float32)</span>
</code></pre>
<p>With the generic version, a bias is just an input with a fixed value of 1 and a
corresponding weight:</p>
<pre><code class="language-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">neuron</span><span class="hljs-params">(x, w)</span>:</span>
    y = <span class="hljs-number">0</span>
    n = len(x)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
        y += x[i] * w[i]
    <span class="hljs-keyword">return</span> y

x = [<span class="hljs-number">1</span>, BLACK]
w = [b, w]

neuron(x, w)

<span class="hljs-comment">#&gt; array([[ 0.97386539]], dtype=float32)</span>
</code></pre>

		</div>
	</body>
	</html>
	